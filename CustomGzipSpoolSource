package com.tcs.flume.source;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.Reader;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.HashMap;
import java.util.Map;

import org.apache.log4j.Logger;
import org.apache.log4j.PropertyConfigurator;
import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.event.EventBuilder;
import org.apache.flume.conf.Configurable;
import org.apache.flume.source.AbstractSource;
import org.apache.flume.PollableSource;
import org.apache.flume.EventDeliveryException;

import java.util.zip.GZIPInputStream;

import com.tcs.flume.source.helper.SpoolDirectoryFileLister;



public class CustomGzipSpoolSource extends AbstractSource 
implements Configurable, PollableSource 
{
	final static Logger logger = Logger.getLogger(CustomGzipSpoolSource.class);
	private String spoolPath;
	private String localPersistPath;

	private SpoolDirectoryFileLister sshClient ;
	private CustomGzipSpoolStateManager filesState;

	@Override
	public void configure(Context context) {

		PropertyConfigurator.configure("log4j.properties");

		spoolPath  = context.getString( CustomGzipSpoolSourceConstants.LOCAL_DIR_PATH );
		localPersistPath = context.getString( CustomGzipSpoolSourceConstants.LOCAL_PERSIST_PATH );

		sshClient  =  new SpoolDirectoryFileLister();
		filesState =  new CustomGzipSpoolStateManager( localPersistPath );
	}

	@Override
	public void start() { }

	@Override
	public void stop () {
		filesState.saveState();
	}

	@Override
	public Status process() throws EventDeliveryException {

		// Get pending files
		PropertyConfigurator.configure("log4j.properties");

		ArrayList< String > pendingFiles;
		try {

			ArrayList< String > files = sshClient.getFilesInPath( spoolPath );
			filesState.addProcessingList( files );

			System.out.println("Files received and aded to processing list");
			pendingFiles = filesState.getPending();

		} catch (Exception e) {
			logger.error( e.toString() );
			return Status.BACKOFF;
		}   

		// Start transaction
		for( String file: pendingFiles )
		{
			try {

				filesState.markInProcess( file );			
				long startTime = System.currentTimeMillis();
				File tempFile = sshClient.getTempLocalInstance( file );
				//File statsFile = sshClient.getTempLocalInstance( file + ".stats");
				if( tempFile == null ) {
					System.out.println("Error in file reading");
					logger.error( "Unable to retrieve contents: " + file );
					logger.error( "Marking file in error state: " + file );
					filesState.markError( file );
					continue;
				}

				Path p = Paths.get(file);
				String file1 = p.getFileName().toString();
				String[] fields = file1.split("_");
				String location = fields[0].split("-")[1];
				String timestamp = fields[1]+fields[2].split("//.")[0];
				System.out.println("The business timestamp is"+timestamp );
				SimpleDateFormat df = new SimpleDateFormat("yyyyMMddHHmmss");
				Date date = df.parse(timestamp);
				long epoch = date.getTime();
				Map< String, String > headers = new HashMap< String, String >();
				headers.put("timestamp",Long.toString(epoch));
				//headers.put( "filename", file );
				headers.put("location", location);
			


				logger.info("File size: " + tempFile.length());
				GZIPInputStream input=null;

				try {
					logger.info("Starting gziping file" + tempFile);
					input = new GZIPInputStream(new FileInputStream(tempFile));
				} catch (FileNotFoundException e) {
					logger.error("GZIP 1 "+e);
					e.printStackTrace();
				} catch (IOException e) {
					logger.error("GZIP 2 "+e);
					e.printStackTrace();
				}

				String content;

				Reader decoder = new InputStreamReader(input);
				BufferedReader br = new BufferedReader(decoder);

				Event e=null;
				int failedlines=0,loaded_lines=0,total_lines=0;
				while ((content = br.readLine()) != null) 
				{
					logger.info("Starting Processing of json document" + tempFile);
					Jsonloader json = new Jsonloader();
					String jsonoutput = json.exec(content);
					if(jsonoutput.equalsIgnoreCase(null)){
						logger.info("Error while performing ETL. The content is: " + content + ". File name is: "+ tempFile);
						failedlines++;
					}
					else if(jsonoutput.equalsIgnoreCase("NOTVALID")){
						logger.info("Error while performing ETLbecause of invalid json. The content is: " + content + ". File name is: "+ tempFile);
						failedlines++;
					}
					else{
						e = EventBuilder.withBody( jsonoutput, CustomGzipSpoolSourceConstants.FILE_CHARSET, headers );
						getChannelProcessor().processEvent(e);
						loaded_lines++;						
					}
					total_lines++;
					System.out.println("Completed Processing of json document");
				}

				if(sshClient.statsGenerator(loaded_lines,failedlines,file)==true)
				{
					logger.info("Stats file has been successfully created for the file "+file );
				}
				else
				{
					logger.warn("Errors in generating stats file for the file"+file);
				}

				filesState.markFinished( file );
				long endTime   = System.currentTimeMillis();
				logger.info("Successfully parsed: " + file );

				long totalTime = startTime - endTime;
				System.out.println("The total duration is"+totalTime);
				if(sshClient.auditGenerator( file, spoolPath, timestamp, total_lines,loaded_lines, failedlines, startTime, endTime,totalTime)==true)
				{
					logger.info("Audit file has been successfully created for the file "+file );
				}
				else
				{
					logger.warn("Errors in generating audit file for the file"+file);
				}

			} catch (Throwable t) {
				// Log exception, handle individual exceptions as needed
				logger.error( "While processing: " + file + " - " + t.toString() );
				filesState.markError( file );
			} 
		}
		return Status.READY;
	}
}
